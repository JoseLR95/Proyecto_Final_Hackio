{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c68eddfa",
   "metadata": {},
   "source": [
    "## Proyecto Final Hackio - Informe temporada 2015/2016 Athletic Club"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae428993",
   "metadata": {},
   "source": [
    "#### Extracción Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb5fc5d",
   "metadata": {},
   "source": [
    "- Eventos partidos (statsbomb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c47b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "\n",
    "from statsbombpy import sb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Extracción datos desde API statsbomb\n",
    "\n",
    "competiciones = sb.competitions() # Competiciones disponibles\n",
    "df_LaLiga = competiciones[competiciones[\"competition_id\"] == 11] # Filtro por La Liga\n",
    "\n",
    "# Conseguir el ID de cada partido\n",
    "df_partidos = pd.DataFrame()\n",
    "for x in df_LaLiga[\"season_id\"]:\n",
    "    df_temporal = sb.matches(competition_id=11, season_id = x)\n",
    "    df_partidos = pd.concat([df_partidos, df_temporal], ignore_index=True)\n",
    "liga2015 = df_partidos[df_partidos[\"season\"] == \"2015/2016\"]\n",
    "lista_2015 = []\n",
    "for x in liga2015[\"match_id\"]:\n",
    "    lista_2015.append(x)\n",
    "\n",
    "# Extraer los eventos de cada partido\n",
    "df_eventos_liga2015 = pd.DataFrame() # Crear DataFrame\n",
    "errores = [] # Aculumar los Ids de partido que puedan dar fallo para recuperarlos posteriormente\n",
    "for x in lista_2015: # Iterar sobre la lista de partidos para extraer cada Id\n",
    "    try:\n",
    "        evento= sb.events(match_id=x)\n",
    "        df_temp = evento # Crear un df temporal con los eventos del partido\n",
    "        df_eventos_liga2015 = pd.concat([df_eventos_liga2015, df_temp], ignore_index=True) # Concatenar con df para guardar el partido\n",
    "        time.sleep(0.5)\n",
    "        time.sleep(0.5)\n",
    "    except Exception as e:\n",
    "        errores.append(x)\n",
    "\n",
    "# Guardar archivo\n",
    "df_eventos_liga2015.to_csv(\"../Data/df_eventos_liga2015.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5d8c22",
   "metadata": {},
   "source": [
    "* Información jugadores (API Transfermarkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484a02ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Extraer la tabla de equipos\n",
    "url = \"https://transfermarket.p.rapidapi.com/competitions/get-table\"\n",
    "rapidapi_key_1 = os.getenv(\"rapidapi-key_1\")\n",
    "querystring = {\"id\":\"ES1\",\"seasonID\":\"2015\",\"domain\":\"es\"}\n",
    "headers = {\n",
    "\t\"x-rapidapi-key\": rapidapi_key_1,\n",
    "\t\"x-rapidapi-host\": \"transfermarket.p.rapidapi.com\"\n",
    "}\n",
    "response = requests.get(url, headers=headers, params=querystring)\n",
    "# Almacenar resultados en variable\n",
    "tabla = response.json()\n",
    "# Extraer ids de equipo dentro de la tabla\n",
    "lista_ids = []\n",
    "for x in tabla[\"table\"]:\n",
    "     lista_ids.append(x[\"id\"])\n",
    "# Extraer los equipos\n",
    "equipos = {}\n",
    "for x in lista_ids:\n",
    "\n",
    "    url = \"https://transfermarket.p.rapidapi.com/clubs/get-squad\"\n",
    "\n",
    "    querystring = {\"id\": str(x),\"saison_id\":\"2015\",\"domain\":\"es\"}\n",
    "\n",
    "    headers = {\n",
    "        \"x-rapidapi-key\": rapidapi_key_1,\n",
    "        \"x-rapidapi-host\": \"transfermarket.p.rapidapi.com\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "    equipos[x] = response.json()\n",
    "\n",
    "# Extraer cada jugador\n",
    "lista_jug_ids = []\n",
    "for x, i in equipos.items():\n",
    "    for x, i in i.items():\n",
    "        for x in i:\n",
    "            lista_jug_ids.append(x[\"id\"])\n",
    "\n",
    "jugadores = {}\n",
    "for x in lista_jug_ids:\n",
    "\n",
    "    url = \"https://transfermarket.p.rapidapi.com/players/get-profile\"\n",
    "\n",
    "    querystring = {\"id\":str(x),\"domain\":\"es\"}\n",
    "\n",
    "    headers = {\n",
    "        'x-rapidapi-key': rapidapi_key_1,\n",
    "        'x-rapidapi-host': \"transfermarket.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "    jugadores[x] = response.json()\n",
    "    if response.status_code == 200:\n",
    "        print(f\"añadido {x}\")\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "\n",
    "no_añadidos = []\n",
    "for a, b in jugadores.items():\n",
    "    for c, d in b.items():\n",
    "        if c == \"message\":\n",
    "            no_añadidos.append(a)\n",
    "\n",
    "for x in no_añadidos:\n",
    "\n",
    "    url = \"https://transfermarket.p.rapidapi.com/players/get-profile\"\n",
    "\n",
    "    querystring = {\"id\":str(x),\"domain\":\"es\"}\n",
    "\n",
    "    headers = {\n",
    "        'x-rapidapi-key': rapidapi_key_1,\n",
    "        'x-rapidapi-host': \"transfermarket.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "    jugadores[x] = response.json()\n",
    "    if response.status_code == 200:\n",
    "        print(f\"añadido {x}\")\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "\n",
    "# Añadir aquellos que han dado fallo\n",
    "for x in no_añadidos:\n",
    "\n",
    "    url = \"https://transfermarket.p.rapidapi.com/players/get-profile\"\n",
    "    rapidapi_key_2 = os.getenv(\"rapidapi_key_2\")\n",
    "    querystring = {\"id\":str(x),\"domain\":\"es\"}\n",
    "\n",
    "    headers = {\n",
    "        'x-rapidapi-key': rapidapi_key_2,\n",
    "        'x-rapidapi-host': \"transfermarket.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "    jugadores[x] = response.json()\n",
    "    if response.status_code == 200:\n",
    "        print(f\"añadido {x}\")\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "\n",
    "# Almacenar los datos\n",
    "data = []\n",
    "for jugador_id, info in jugadores.items():\n",
    "    perfil = info.get(\"playerProfile\", {})\n",
    "    data.append(perfil)\n",
    "\n",
    "# Crear el DataFrame\n",
    "df_jugadores = pd.DataFrame(data)\n",
    "\n",
    "# Guardar archivo\n",
    "df_jugadores.to_csv(\"data/jugadores_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d7a529",
   "metadata": {},
   "source": [
    "* Datos equipos (API FBREF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d25a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import time\n",
    "\n",
    "# Conseguir los IDs de equipo para API\n",
    "lista_ligas = {\"2015-2016\": \"https://fbref.com/es/comps/12/2015-2016/Estadisticas-2015-2016-La-Liga\"}\n",
    "lista_equipos = {}\n",
    "for a, x in lista_ligas.items():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    url = x\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    # Buscar todos los enlaces de equipos\n",
    "    tabla = driver.find_element(By.CSS_SELECTOR, \"table.stats_table.sortable.min_width.force_mobilize.now_sortable\")\n",
    "    enlaces = tabla.find_elements(By.CSS_SELECTOR, 'a[href*=\"/es/equipos/\"]')\n",
    "\n",
    "    equipos = []\n",
    "\n",
    "    for enlace in enlaces:\n",
    "        href = enlace.get_attribute(\"href\")\n",
    "        texto = enlace.text.strip()\n",
    "        \n",
    "        partes = href.split(\"/\")\n",
    "\n",
    "        try:\n",
    "            idx = partes.index(\"equipos\")\n",
    "            id_equipo = partes[idx + 1]  # El ID está justo después de \"equipos\"\n",
    "            equipos.append(id_equipo)\n",
    "        except (ValueError, IndexError):\n",
    "            continue  # Si no encuentra \"equipos\" o el ID está mal formado\n",
    "    driver.quit()\n",
    "    time.sleep(5)\n",
    "    lista_equipos[a] = equipos\n",
    "\n",
    "# Generar API-Key\n",
    "response = requests.post('https://fbrapi.com/generate_api_key')\n",
    "api_key = response.json()['api_key']\n",
    "\n",
    "# Conseguir información de cada equipo\n",
    "url = \"https://fbrapi.com/teams\"\n",
    "jugadores = {}\n",
    "no_añadidos = {}\n",
    "headers = {\"X-API-Key\": api_key}\n",
    "\n",
    "for temporada, lista_ids in lista_equipos.items():  # lista_ids es una lista de team_ids\n",
    "    for team_id in lista_ids:\n",
    "        params = {\n",
    "            \"team_id\": team_id,\n",
    "            \"season_id\": temporada\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(url, params=params, headers=headers)\n",
    "            print(f\"Equipo {team_id}, Año {temporada}, Status: {response.status_code}\")\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                if temporada not in jugadores:\n",
    "                    jugadores[temporada] = {}  # lista de equipos para esa temporada\n",
    "                jugadores[temporada][team_id] = response.json()\n",
    "            else:\n",
    "                if temporada not in no_añadidos:\n",
    "                    no_añadidos[temporada] = {}\n",
    "                no_añadidos[temporada].append(team_id)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en temporada {temporada}, equipo {team_id}: {e}\")\n",
    "            if temporada not in no_añadidos:\n",
    "                no_añadidos[temporada] = {}\n",
    "            no_añadidos[temporada].append(team_id)\n",
    "        time.sleep(6)  # por si hay límite de llamadas\n",
    "\n",
    "# Guardar jugadores\n",
    "df_jugadores = []\n",
    "for x, i in jugadores.items():  # x = temporada, i = diccionario de equipos\n",
    "    for a, b in i.items():      # a = team_id, b = contenido (team_roster, team_schedule)\n",
    "        c = b[\"team_roster\"]\n",
    "        for d, e in c.items():  # c debería ser \"data\"\n",
    "            for f in e:  # e = jugador (diccionario)\n",
    "                f[\"season_id\"] = x\n",
    "                f[\"team_id\"] = a\n",
    "                df_jugadores.append(f)\n",
    "\n",
    "# Crear el DataFrame\n",
    "df_jugadores = pd.DataFrame(df_jugadores)  \n",
    "\n",
    "# Extraer estadísticas de temporada de cada jugador\n",
    "url = \"https://fbrapi.com/player-season-stats\"\n",
    "headers = {\"X-API-Key\": api_key}\n",
    "data_jugadores = {}\n",
    "for x, i in lista_equipos.items():\n",
    "    for team_id in i:\n",
    "        params = {\n",
    "        \"team_id\": team_id,\n",
    "        \"league_id\": 12,\n",
    "        \"season_id\": \"2015-2016\"}\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            data_jugadores[team_id] = response.json()\n",
    "        time.sleep(3)\n",
    "for team_id, team_info in data_jugadores.items():\n",
    "    print(team_info)\n",
    "    for player in team_info['players']:\n",
    "        print(player)\n",
    "# Lista para almacenar los datos de cada jugador\n",
    "players_data = []\n",
    "\n",
    "# Iteramos sobre cada equipo en el diccionario\n",
    "for team_id, team_info in data_jugadores.items():\n",
    "    # Iteramos sobre cada jugador en el equipo\n",
    "    for player in team_info['players']:\n",
    "        # Creamos un diccionario base con el ID del equipo\n",
    "        player_dict = {'team_id': team_id}\n",
    "        \n",
    "        # Añadimos todos los campos de meta_data con prefijo 'meta_'\n",
    "        for key, value in player['meta_data'].items():\n",
    "            player_dict[f'{key}'] = value\n",
    "        \n",
    "        # Añadimos todos los campos de stats.stats con prefijo 'stats_'\n",
    "        for key, value in player['stats']['stats'].items():\n",
    "            player_dict[f'{key}'] = value\n",
    "        \n",
    "        # Añadimos todos los campos de stats.playingtime con prefijo 'playingtime_'\n",
    "        for key, value in player['stats']['playingtime'].items():\n",
    "            player_dict[f'{key}'] = value\n",
    "        \n",
    "        # Añadimos este jugador a la lista\n",
    "        players_data.append(player_dict)\n",
    "\n",
    "# Creamos el DataFrame\n",
    "df_info = pd.DataFrame(players_data)\n",
    "# Eliminamos duplicados\n",
    "df_info = df_info.dropna(subset=['player_id'])\n",
    "\n",
    "# Guardamos archivo\n",
    "df_info.to_csv(\"data/jugadores_LaLiga_completo.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5550df",
   "metadata": {},
   "source": [
    "* Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923dfbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import time\n",
    "import re\n",
    "from statsbombpy import sb\n",
    "import src as src\n",
    "from src import normalizacion_nombres\n",
    "\n",
    "# Crear URLs para cada jornada\n",
    "contador = 0\n",
    "plantilla_url = \"https://www.ceroacero.es/edicion/campeonato-espanhol-2015-16/87618?jornada_in={x}&fase=82379\"\n",
    "urls_por_jornada = {}\n",
    "for contador in range(0,38):\n",
    "    url = plantilla_url.format(x=contador+1)\n",
    "    urls_por_jornada[contador+1] = url\n",
    "\n",
    "# Configuración del navegador\n",
    "service = Service(ChromeDriverManager().install())\n",
    "options = Options()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "df_jornadas = pd.DataFrame()\n",
    "for x, i in urls_por_jornada.items():\n",
    "    # URL\n",
    "    base_url = i\n",
    "    driver.get(base_url)\n",
    "    datos = []\n",
    "    encabezado = []\n",
    "    # Espera\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    # Clic en el botón de cookies\n",
    "    try:\n",
    "        cookie_button = driver.find_element(By.CSS_SELECTOR, \".fc-button-label\")\n",
    "        cookie_button.click()\n",
    "    except:\n",
    "        pass  # En caso de que no aparezca seguir con el código\n",
    "    try:\n",
    "        cookie_button2 = driver.find_element(By.CSS_SELECTOR, \".ns-xhr8a-e-16\")\n",
    "        cookie_button2.click()\n",
    "    except:\n",
    "        pass  # En caso de que no aparezca seguir con el código\n",
    "\n",
    "    # Buscar clasificacion\n",
    "    tabla_element = wait.until(EC.presence_of_element_located((By.ID, \"DataTables_Table_0\")))\n",
    "    if not encabezado: # Solo la primera vez\n",
    "        headers_th = tabla_element.find_elements(By.XPATH, \".//thead/tr/th\")\n",
    "        # Priorizar el texto del 'aria-label' si el texto normal está vacío o es genérico\n",
    "        # O simplemente tomar el texto visible\n",
    "        for th in headers_th:\n",
    "            aria_label = th.get_attribute(\"aria-label\")\n",
    "            text = th.text.strip()\n",
    "            if text and text not in [\":\", \"\"]: # Usar texto si es significativo\n",
    "                encabezado.append(text)\n",
    "            elif aria_label and \":\" in aria_label: # Procesar aria-label\n",
    "                    # \"Pts: activate to sort column ascending\" -> \"Pts\"\n",
    "                encabezado.append(aria_label.split(\":\")[0].strip())\n",
    "            elif text: # Fallback a texto si aria-label no es útil\n",
    "                encabezado.append(text)\n",
    "            else: # Si ambos son malos, un placeholder o intentar inferir\n",
    "                encabezado.append(f\"Col_{len(encabezado)+1}\") # Placeholder\n",
    "\n",
    "        # Limpieza de posibles columnas vacías o no deseadas del final si tienen placeholders\n",
    "        if encabezado and encabezado[-1].startswith(\"Col_\"):\n",
    "            # La última columna parece ser de acciones, la removemos si no tiene un buen nombre\n",
    "                is_action_col = tabla_element.find_elements(By.XPATH, \".//tbody/tr[1]/td[last()]/a/span[contains(@class, 'icn_zerozero')]\")\n",
    "                if is_action_col:\n",
    "                    encabezado.pop()\n",
    "\n",
    "        # Asegurarse de que los nombres de las columnas sean únicos si es necesario\n",
    "        # y que coincidan con el número de celdas que planeas extraer.\n",
    "        # Por la estructura de la tabla HTML, el nombre del equipo está en la 3ra columna visual,\n",
    "        # pero la 2da <th> puede estar vacía (para el logo).\n",
    "        # Ajuste manual si es necesario, basado en la inspección visual de la tabla:\n",
    "        # Ejemplo de ajuste si los nombres automáticos no son perfectos:\n",
    "        expected_cols = [\"Pos\", \"Logo\", \"Equipo\", \"Pts\", \"P\", \"V\", \"E\", \"D\", \"GM\", \"GR\", \"DG\"] # Menos la última de acción\n",
    "        if len(encabezado) >= len(expected_cols):\n",
    "                # La primera columna <th> es para Pos, la segunda para Logo (sin texto), la tercera para Equipo (texto vacío)\n",
    "                # Usaremos una lista predefinida para mayor robustez con esta tabla específica.\n",
    "                column_headers = expected_cols\n",
    "\n",
    "\n",
    "    # Extraer filas de datos\n",
    "    filas = tabla_element.find_elements(By.XPATH, \".//tbody/tr\")\n",
    "    #print(f\"Encontradas {len(filas)} filas en Jornada {i+1}.\")\n",
    "\n",
    "    for fila in filas:\n",
    "        celdas = fila.find_elements(By.TAG_NAME, \"td\")\n",
    "        if len(celdas) >= len(column_headers): # Asegurar que hay suficientes celdas\n",
    "            # Extraer el texto de cada celda. Adaptar según la estructura.\n",
    "            # La columna del equipo (índice 2) tiene un enlace <a>\n",
    "            posicion = celdas[0].text.strip()\n",
    "            # logo_img_src = celdas[1].find_element(By.TAG_NAME, \"img\").get_attribute(\"src\") # Opcional\n",
    "            equipo_link = celdas[2].find_element(By.TAG_NAME, \"a\")\n",
    "            equipo = equipo_link.text.strip()\n",
    "            # equipo_url = equipo_link.get_attribute(\"href\") # Opcional\n",
    "\n",
    "            # Resto de las celdas (Pts, P, V, E, D, GM, GR, DG)\n",
    "            # Índices 3 a 10 para los datos si column_headers tiene 11 elementos\n",
    "            datos_numericos = [celda.text.strip() for celda in celdas[3:len(column_headers)]]\n",
    "\n",
    "\n",
    "            registro = [posicion, \"logo_placeholder\", equipo] + datos_numericos\n",
    "            registro_dict = dict(zip(column_headers, registro))\n",
    "            registro_dict['Jornada'] = x # Añadir la jornada actual\n",
    "            datos.append(registro_dict)\n",
    "        #else:\n",
    "            #print(f\"Fila omitida en Jornada {i+1} por no tener suficientes celdas: {[c.text for c in celdas]}\")\n",
    "\n",
    "\n",
    "    # 5. Convertir a DataFrame de Pandas y guardar (opcional)\n",
    "    if datos:\n",
    "        df = pd.DataFrame(datos)\n",
    "        df_jornadas = pd.concat([df_jornadas, df], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# 4. Cerrar el WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Eliminar columnas no necesarias\n",
    "df_jornadas.drop(columns=([\"Logo\"]), inplace=True)\n",
    "\n",
    "# Normalizar los nombres de los equipos y columnas\n",
    "df_wyscout = pd.read_csv(\"data/Tabla_Partidos.csv\")\n",
    "clubs_statsbomb = df_wyscout[\"Local\"].unique().tolist()\n",
    "clubs_jornadas = df_jornadas[\"Equipo\"].unique().tolist()\n",
    "df_clubes = src.normalizacion_nombres(clubs_statsbomb, clubs_jornadas)\n",
    "# Crear diccionario\n",
    "dict_nombres_equipos = dict(zip(df_clubes[\"Nombre_unificado\"], df_clubes[\"Nombre_original\"]))\n",
    "# Mapear nombres en todas las columnas\n",
    "df_jornadas[\"Equipo\"] = df_jornadas[\"Equipo\"].map(dict_nombres_equipos)\n",
    "df_combinado = df_jornadas.merge(\n",
    "    df_wyscout[[\"Local\", \"id_club_local_L\"]],\n",
    "    left_on=[\"Equipo\"],\n",
    "    right_on=[\"Local\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "df_combinado.drop(columns=([\"Local\"]), inplace=True)\n",
    "df_combinado.rename(columns=({\"id_club_local_L\":\"clubid\"}), inplace=True)\n",
    "\n",
    "# Guardar archivo\n",
    "df_combinado.to_csv(\"data/clasificacion.csv\" ,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89346857",
   "metadata": {},
   "source": [
    "* Lesiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b78ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Conseguir cada URL del equipo y sus nombres\n",
    "lista_equipos_urls = []\n",
    "equipos_nombres = {}\n",
    "# Configuración del navegador\n",
    "service = Service(ChromeDriverManager().install())\n",
    "options = Options()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "# URL\n",
    "base_url = \"https://www.ceroacero.es/edicion/campeonato-espanhol-2015-16/87618\"\n",
    "driver.get(base_url)\n",
    "# Espera\n",
    "wait = WebDriverWait(driver, 10)\n",
    "# Clic en el botón de cookies\n",
    "try:\n",
    "    cookie_button = driver.find_element(By.CSS_SELECTOR, \".fc-button-label\")\n",
    "    cookie_button.click()\n",
    "except:\n",
    "    pass  # En caso de que no aparezca seguir con el código\n",
    "try:\n",
    "    cookie_button2 = driver.find_element(By.CSS_SELECTOR, \".ns-xhr8a-e-16\")\n",
    "    cookie_button2.click()\n",
    "except:\n",
    "    pass  # En caso de que no aparezca seguir con el código\n",
    "\n",
    "# Buscar todos los enlaces de equipos\n",
    "tabla = driver.find_element(By.CSS_SELECTOR, \"table.zztable.stats.zz-datatable.dataTable.no-footer\")\n",
    "enlaces = tabla.find_elements(By.CSS_SELECTOR, 'a[href*=\"/equipo/\"]')\n",
    "for enlace in enlaces:\n",
    "    href = enlace.get_attribute(\"href\")\n",
    "    equipo = href.split(\"/equipo/\")[1].split(\"?\")[0].rstrip(\"/\")\n",
    "    if equipo not in lista_equipos_urls:\n",
    "        lista_equipos_urls.append(equipo)\n",
    "    nombre = enlace.text\n",
    "    equipos_nombres[equipo] = nombre\n",
    "driver.quit()\n",
    "\n",
    "# Crear URL personalizada de cada equipo\n",
    "plantilla_url = \"https://www.ceroacero.es/equipo/{x}/unavailable?epoca_sidelines_id=145\"\n",
    "\n",
    "urls_por_equipo = {}\n",
    "\n",
    "for equipo in lista_equipos_urls:\n",
    "    if equipo == \"athletic-bilbao\":\n",
    "        equipo = \"athletic\"\n",
    "    url = plantilla_url.format(x=equipo)\n",
    "    urls_por_equipo[equipo] = url\n",
    "\n",
    "\n",
    "# Conseguir Dataframe final\n",
    "df_lesiones_equipo = pd.DataFrame()\n",
    "service = Service(ChromeDriverManager().install())\n",
    "options = Options()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "wait = WebDriverWait(driver, 10)\n",
    "for x, i in urls_por_equipo.items():\n",
    "\n",
    "    dictio = {\"columnas\": [], \"datos\": []}\n",
    "    driver.get(i)\n",
    "    # Clic en el botón de cookies\n",
    "    try:\n",
    "        driver.find_element(By.CSS_SELECTOR, \".fc-button-label\").click()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        driver.find_element(By.CSS_SELECTOR, \".ns-xhr8a-e-16\").click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(5)\n",
    "    # Obtener la tabla\n",
    "    info = driver.find_elements(By.CSS_SELECTOR, \"table.zz-datatable.zztable.stats\")\n",
    "    for item in info:\n",
    "        columnas = [th.text.strip() for th in item.find_elements(By.CSS_SELECTOR, \"th\")]\n",
    "        dictio[\"columnas\"].extend(columnas + [\"href\"])\n",
    "        filas = item.find_elements(By.CSS_SELECTOR, \"tbody tr\")\n",
    "        for fila in filas:\n",
    "            datos = [td.text.strip() for td in fila.find_elements(By.CSS_SELECTOR, \"td\")]\n",
    "            enlace_jugador = fila.find_element(By.CSS_SELECTOR, 'a[href*=\"/jugador/\"]')\n",
    "            href = enlace_jugador.get_attribute(\"href\")\n",
    "            datos.append(href)\n",
    "            dictio[\"datos\"].append(datos)\n",
    "    # Guardar DataFrame temporal\n",
    "    if dictio[\"datos\"]:\n",
    "        df_temporal = pd.DataFrame(dictio[\"datos\"], columns=dictio[\"columnas\"])\n",
    "        df_temporal[\"equipo\"] = x\n",
    "        df_lesiones_equipo = pd.concat([df_lesiones_equipo, df_temporal], ignore_index=True)\n",
    "    print(f\"Datos de {x} desde {i}\")\n",
    "driver.quit()\n",
    "\n",
    "# Hacer diccionario para los nombres completos de cada jugador (href)\n",
    "df_jugadores_href = df_lesiones_equipo[[\"JUGADOR\", \"href\"]].drop_duplicates()\n",
    "diccionario_jugadores = df_jugadores_href.set_index(\"JUGADOR\")[\"href\"].to_dict()\n",
    "\n",
    "# Hacer diccionario con nombre de cada jugador\n",
    "service = Service(ChromeDriverManager().install())\n",
    "options = Options()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "wait = WebDriverWait(driver, 10)\n",
    "dictio_jugadores = {}\n",
    "for nombre, url in diccionario_jugadores.items():\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        driver.find_element(By.CSS_SELECTOR, \".fc-button-label\").click()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        driver.find_element(By.CSS_SELECTOR, \".ns-xhr8a-e-16\").click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(2)\n",
    "    tabla = driver.find_elements(By.CSS_SELECTOR, \"#entity_bio.frame\")\n",
    "    nombre_elemento = tabla[0].find_elements(By.CSS_SELECTOR, \".bio\")[0]\n",
    "    jugador1 = nombre_elemento.text.split(\"NOMBRE\")[1]\n",
    "    jugador = jugador1.split(\"\\n\")[1]\n",
    "    dictio_jugadores[nombre] = jugador\n",
    "driver.quit()\n",
    "\n",
    "# Mapear columnas\n",
    "df_lesiones_equipo[\"href\"] = df_lesiones_equipo[\"JUGADOR\"].map(dictio_jugadores)\n",
    "df_lesiones_equipo[\"equipo\"] = df_lesiones_equipo[\"equipo\"].map(equipos_nombres)\n",
    "\n",
    "# Guardar archivo\n",
    "df_lesiones_equipo.to_csv(\"data/lesiones_completo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9730b5",
   "metadata": {},
   "source": [
    "#### Normalización Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc04a06",
   "metadata": {},
   "source": [
    "* Jugadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae8ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import src as src\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Cargar archivos\n",
    "df_eventos = pd.read_csv(\"data/df_eventos_liga2015.csv\")\n",
    "df_jugadores_info = pd.read_csv(\"data/jugadores_info.csv\")\n",
    "\n",
    "# Cambiar el primer 'Sergio Alvarez' (duplicado)\n",
    "sergio_idx = df_jugadores_info[df_jugadores_info['playerFullName'] == 'Sergio Álvarez'].index[0]\n",
    "df_jugadores_info.at[sergio_idx, 'playerFullName'] = 'Sergio Álvarez Conde'\n",
    "# Cambiar el primer 'Pablo Hernandez' (duplicado)\n",
    "pablo_idx = df_jugadores_info[df_jugadores_info['playerFullName'] == 'Pablo Hernández'].index[0]\n",
    "df_jugadores_info.at[pablo_idx, 'playerFullName'] = 'Pedro Pablo Hernández'\n",
    "# Cambiar el primer 'Pedro López' (duplicado)\n",
    "pedro_idx = df_jugadores_info[df_jugadores_info['playerFullName'] == 'Pedro López'].index[1]\n",
    "df_jugadores_info.at[pedro_idx, 'playerFullName'] = 'Pedro López Muñoz'\n",
    "\n",
    "# Crear listas de los nombres y equipo que aparecen en cada df\n",
    "df_jugadoresunicos_eventos = df_eventos[\"player\"].unique().tolist()\n",
    "df_jugadoresunicos_info = df_jugadores_info[\"playerFullName\"].unique().tolist()\n",
    "df_clubesunicos_eventos = df_eventos[\"team\"].unique().tolist()\n",
    "df_clubesunicos_info = df_jugadores_info[\"club\"].unique().tolist()\n",
    "\n",
    "# Normalizar con función\n",
    "df_nombres = src.normalizacion_nombres(df_jugadoresunicos_info, df_jugadoresunicos_eventos)\n",
    "df_clubes = src.normalizacion_nombres(df_clubesunicos_info, df_clubesunicos_eventos)\n",
    "# Crear diccionario para mapear los nombres\n",
    "dict_nombres_info = df_nombres.set_index('Nombre_original')['Nombre_unificado'].to_dict()\n",
    "# Mapear nombres jugadores\n",
    "df_jugadores_info[\"playerFullName\"] = df_jugadores_info[\"playerFullName\"].apply(\n",
    "    lambda x: dict_nombres_info.get(x, x) if dict_nombres_info.get(x) is not None else x)\n",
    "# Crear diccionario para mapear los equipos\n",
    "df_equipos_jugadores = df_eventos[[\"player\", \"team\"]].drop_duplicates()\n",
    "dict_equipos_jugadores = dict(zip(df_equipos_jugadores[\"player\"], df_equipos_jugadores[\"team\"]))\n",
    "# Mapear los equipos en la temporada 2015/2016 ya que la info que aparece es actual\n",
    "df_jugadores_info[\"club\"] = df_jugadores_info[\"playerFullName\"].map(dict_equipos_jugadores)\n",
    "# Crear diccionarios para mapear los IDs de jugador y equipo\n",
    "df_equipos = df_eventos[[\"team\", \"team_id\"]].drop_duplicates()\n",
    "dict_equipos = dict(zip(df_equipos[\"team\"], df_equipos[\"team_id\"]))\n",
    "df_jugadores = df_eventos[[\"player\", \"player_id\"]].drop_duplicates()\n",
    "dict_jugadores = dict(zip(df_jugadores[\"player\"], df_jugadores[\"player_id\"]))\n",
    "# Mapear ID Jugadores\n",
    "df_jugadores_info[\"playerID\"] = df_jugadores_info[\"playerFullName\"].map(dict_jugadores)\n",
    "# Mapear ID Equipos\n",
    "df_jugadores_info[\"clubID\"] = df_jugadores_info[\"club\"].map(dict_equipos)\n",
    "# Eliminar columnas no necesarias\n",
    "df_jugadores_info.drop(columns=(['player_name', 'team_id', 'player_country_code', 'age',\n",
    "       'positions', 'unused_sub',\n",
    "       'team_gls_on_pitch', 'team_gls_ag_on_pitch', 'per90_plus_minus',\n",
    "       'per90_on_off']), inplace=True)\n",
    "# Cargar fichero para unir df\n",
    "df_tabla = pd.read_csv(\"data/jugadores_info_normalizado.csv\")\n",
    "df_combinado = df_tabla.merge(\n",
    "    df_jugadores_info,\n",
    "    left_on=[\"playerID\"],\n",
    "    right_on=[\"player_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "# Eliminar duplicados\n",
    "df_combinado.drop(columns=([\"player_id\"]), inplace=True)\n",
    "# Guardar archivo preparado para subir\n",
    "df_combinado.to_csv(\"data/jugadores_info_normalizado.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b3b04a",
   "metadata": {},
   "source": [
    "* Lesiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63149f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import src as src\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Cargar archivos\n",
    "df_eventos = pd.read_csv(\"data/df_eventos_liga2015.csv\")\n",
    "df_lesiones = pd.read_csv(\"data/lesiones_completo.csv\")\n",
    "# Crear listas nombres únicos\n",
    "df_jugadoresunicos_eventos = df_eventos[\"player\"].unique().tolist()\n",
    "df_jugadoresunicos = df_lesiones[\"href\"].unique().tolist()\n",
    "df_clubesunicos_eventos = df_eventos[\"team\"].unique().tolist()\n",
    "df_clubesunicos = df_lesiones[\"equipo\"].unique().tolist()\n",
    "# Aplicar función normalización\n",
    "df_nombres = src.normalizacion_nombres(df_jugadoresunicos, df_jugadoresunicos_eventos)\n",
    "df_clubes = src.normalizacion_nombres(df_clubesunicos, df_clubesunicos_eventos)\n",
    "# Crear diccionario\n",
    "dict_nombres_info = df_nombres.set_index('Nombre_original')['Nombre_unificado'].to_dict()\n",
    "# Mapear nombres\n",
    "df_lesiones[\"href\"] = df_lesiones[\"href\"].apply(\n",
    "    lambda x: dict_nombres_info.get(x, x) if dict_nombres_info.get(x) is not None else x)\n",
    "# Crear diccionario para mapear los equipos\n",
    "df_equipos_jugadores = df_eventos[[\"player\", \"team\"]].drop_duplicates()\n",
    "dict_equipos_jugadores = dict(zip(df_equipos_jugadores[\"player\"], df_equipos_jugadores[\"team\"]))\n",
    "# Mapear los equipos en la temporada 2015/2016 ya que la info que aparece es actual\n",
    "df_lesiones[\"equipo\"] = df_lesiones[\"href\"].map(dict_equipos_jugadores)\n",
    "# Crear diccionarios para mapear los IDs de jugador y equipo\n",
    "df_equipos = df_eventos[[\"team\", \"team_id\"]].drop_duplicates()\n",
    "dict_equipos = dict(zip(df_equipos[\"team\"], df_equipos[\"team_id\"]))\n",
    "df_jugadores = df_eventos[[\"player\", \"player_id\"]].drop_duplicates()\n",
    "dict_jugadores = dict(zip(df_jugadores[\"player\"], df_jugadores[\"player_id\"]))\n",
    "# Mapear ID Jugadores\n",
    "df_lesiones[\"playerID\"] = df_lesiones[\"href\"].map(dict_jugadores)\n",
    "# Mapear ID Equipos\n",
    "df_lesiones[\"clubID\"] = df_lesiones[\"equipo\"].map(dict_equipos)\n",
    "# Crear unicos para lesiones\n",
    "tipo_lesiones_unico = df_lesiones[\"TIPO\"].unique().tolist()\n",
    "subtipo_lesiones_unico = df_lesiones[\"SUB TIPO\"].unique().tolist()\n",
    "dict_subtipo = {}\n",
    "item = 0\n",
    "for x in subtipo_lesiones_unico:\n",
    "    item = item + 1\n",
    "    dict_subtipo[x] = item\n",
    "\n",
    "dict_tipo = {}\n",
    "item_1 = 1\n",
    "for x in tipo_lesiones_unico:\n",
    "    item_1 = item_1 + 1\n",
    "    dict_tipo[x] = item_1\n",
    "\n",
    "# Mapear nombres unificados\n",
    "df_lesiones[\"TIPO_ID\"] = df_lesiones[\"TIPO\"].map(dict_tipo)\n",
    "df_lesiones[\"SUB_TIPO_ID\"] = df_lesiones[\"SUB TIPO\"].map(dict_subtipo)\n",
    "\n",
    "# Guardar archivo\n",
    "df_lesiones.to_csv(\"data/lesiones_completo_normalizado.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89566d86",
   "metadata": {},
   "source": [
    "* Datos Equipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96737019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "from statsbombpy import sb\n",
    "from rapidfuzz import process, fuzz\n",
    "import src as src\n",
    "# Cargar datos y archivos\n",
    "df_statsbomb = sb.matches(competition_id=11, season_id = 27)\n",
    "df_wyscout = pd.read_excel(\"data/Team Stats Consolidado.xlsx\")\n",
    "# Crear listas unicas\n",
    "clubs_statsbomb = df_statsbomb[\"home_team\"].unique().tolist()\n",
    "clubs_wyscout = df_wyscout[\"Local\"].unique().tolist()\n",
    "clubs_wyscout_stats = df_wyscout[\"Stats Equipo\"].unique().tolist()\n",
    "# Eliminar sufijos columnas\n",
    "df_wyscout['Visitante'] = df_wyscout['Visitante'].str.strip()\n",
    "df_wyscout['Local'] = df_wyscout['Local'].str.strip()\n",
    "df_wyscout['Stats Equipo'] = df_wyscout['Stats Equipo'].str.strip()\n",
    "# Normalizar nombres\n",
    "df_clubes = src.normalizacion_nombres(clubs_statsbomb, clubs_wyscout)\n",
    "df_clubes_stats = src.normalizacion_nombres(clubs_wyscout_stats, clubs_statsbomb)\n",
    "# Crear diccionario\n",
    "dict_nombres_equipos = dict(zip(df_clubes[\"Nombre_unificado\"], df_clubes[\"Nombre_original\"]))\n",
    "# Mapear nombres en todas las columnas\n",
    "df_wyscout[\"Local\"] = df_wyscout[\"Local\"].map(dict_nombres_equipos)\n",
    "df_wyscout[\"Visitante\"] = df_wyscout[\"Visitante\"].map(dict_nombres_equipos)\n",
    "# Crear diccionario\n",
    "dict_nombres_equipos_stats = dict(zip(df_clubes_stats[\"Nombre_original\"], df_clubes_stats[\"Nombre_unificado\"]))\n",
    "# Mapear nombres en todas las columnas\n",
    "df_wyscout[\"Stats Equipo\"] = df_wyscout[\"Stats Equipo\"].map(dict_nombres_equipos_stats)\n",
    "# Unir df\n",
    "df_combinado = df_wyscout.merge(\n",
    "    df_statsbomb[[\"home_team\", \"away_team\", \"match_id\"]],\n",
    "    left_on=[\"Local\", \"Visitante\"],\n",
    "    right_on=[\"home_team\", \"away_team\"],\n",
    "    how=\"left\")\n",
    "# Guardar archivos\n",
    "df_combinado.to_csv(\"data/Team_Stats_Normalizado.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a75219",
   "metadata": {},
   "source": [
    "#### Carga Datos BBDD SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad87c5b4",
   "metadata": {},
   "source": [
    "* Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864a16d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src import extraer_coordenadas_manual, insertar_datos_automatico, conexion_postgres\n",
    "import psycopg2\n",
    "pd.set_option('display.max_columns', None)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "# Cargar archivo\n",
    "df_clasificacion = pd.read_csv(\"data/clasificacion.csv\")\n",
    "# Eliminar duplicados\n",
    "df_clasificacion.drop_duplicates(inplace = True)\n",
    "# Hacer index\n",
    "df_clasificacion[\"index\"] = df_clasificacion[\"Jornada\"].astype(str) + \"_\" + df_clasificacion[\"clubid\"].astype(str)\n",
    "# Renombrar columnas\n",
    "df_clasificacion.rename(columns = ({\n",
    "    \"Pts\" : \"Puntos\",\n",
    "    \"P\" : \"Partidos\",\n",
    "    \"V\" : \"Victorias\",\n",
    "    \"E\" : \"Empates\",\n",
    "    \"D\" : \"Derrotas\",\n",
    "    \"GM\" : \"Goles_a_favor\",\n",
    "    \"GR\" : \"Goles_en_contra\",\n",
    "    \"DG\" : \"Diferencia_goles\"\n",
    "}), inplace = True)\n",
    "# Carga BBDD\n",
    "load_dotenv()\n",
    "dbname = os.getenv(\"dbname\")\n",
    "user = os.getenv(\"user\")\n",
    "password = os.getenv(\"password\")\n",
    "(conn,cur) = conexion_postgres(dbname, user, password)\n",
    "insertar_datos_automatico(df_clasificacion,\"clasficacion\", cur, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb71ac6",
   "metadata": {},
   "source": [
    "* Equipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563a532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from src import insertar_datos_automatico, conexion_postgres\n",
    "pd.set_option('display.max_columns', None)\n",
    "import psycopg2\n",
    "# Cargar archivos\n",
    "df_completo = pd.read_csv(\"data/jugadores_info_normalizado.csv\")\n",
    "# Eliminar duplicados\n",
    "df_clubs = df_completo[[\"club\", \"clubID\"]].drop_duplicates().dropna().reset_index().drop(columns = [\"index\"])\n",
    "# Carga BBDD\n",
    "load_dotenv()\n",
    "dbname = os.getenv(\"dbname\")\n",
    "user = os.getenv(\"user\")\n",
    "password = os.getenv(\"password\")\n",
    "(conn,cur) = conexion_postgres(dbname, user, password)\n",
    "insertar_datos_automatico(df_clubs,\"clubes\", cur, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ed7d1",
   "metadata": {},
   "source": [
    "* Eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db5541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src import extraer_coordenadas_manual, insertar_datos_automatico, conexion_postgres\n",
    "import psycopg2\n",
    "pd.set_option('display.max_columns', None)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "# Cargar archivo\n",
    "df_eventos = pd.read_csv(\"data/df_eventos_liga2015.csv\")\n",
    "# Crear Id por tipo de evento\n",
    "dict_id_tipo_evento = {}\n",
    "id_tipo_evento = 1\n",
    "for x in df_eventos[\"type\"].unique().tolist():\n",
    "    dict_id_tipo_evento[x] = id_tipo_evento\n",
    "    id_tipo_evento = id_tipo_evento + 1\n",
    "df_eventos[\"type_id\"] = df_eventos[\"type\"].map(dict_id_tipo_evento)\n",
    "# Eliminar columnas innecesarias\n",
    "df_eventos.drop(columns=(['bad_behaviour_card',\n",
    " 'off_camera',\n",
    " 'related_events',\n",
    " 'substitution_outcome',\n",
    " 'substitution_outcome_id',\n",
    " 'substitution_replacement',\n",
    " 'substitution_replacement_id',\n",
    " 'shot_freeze_frame',\n",
    " '50_50',\n",
    " 'index',\n",
    " 'duration',\n",
    " 'tactics',\n",
    " \"pass_angle\",\n",
    " \"pass_length\",\n",
    " \"minute\",\n",
    " \"second\",\n",
    " 'injury_stoppage_in_chain',\n",
    " 'player_off_permanent',\n",
    " 'half_end_early_video_end']), inplace=True)\n",
    "\n",
    "# Crear columnas coordenadas\n",
    "lista_col_location = []\n",
    "for col in df_eventos.columns:\n",
    "    if \"location\" in col:\n",
    "        lista_col_location.append(col)\n",
    "for loc_col_name in lista_col_location:\n",
    "    # Nombres para las nuevas columnas de x e y\n",
    "    nueva_col_x = f\"{loc_col_name}_x\"\n",
    "    nueva_col_y = f\"{loc_col_name}_y\"\n",
    "    nueva_col_z = f\"{loc_col_name}_z\"\n",
    "    # Aplicar la función y asignar a las nuevas columnas\n",
    "    df_eventos[[nueva_col_x, nueva_col_y, nueva_col_z]] = df_eventos[loc_col_name].apply( lambda val: pd.Series(extraer_coordenadas_manual(val)))\n",
    "lista_drop = []\n",
    "for drop in df_eventos.columns:\n",
    "    if drop.startswith(\"shot\"):\n",
    "        continue\n",
    "    if \"location\" in drop and drop.endswith(\"z\"):\n",
    "        lista_drop.append(drop)\n",
    "df_eventos.drop(columns=lista_drop, inplace=True)\n",
    "df_eventos.drop(columns=lista_col_location, inplace=True)\n",
    "\n",
    "# Modificar columnas booleanas y numericas con NaN para pasar a None\n",
    "columnas_bool = []\n",
    "\n",
    "for col in df_eventos.columns:\n",
    "    if df_eventos[col].apply(lambda x: isinstance(x, bool) and x is True).any():\n",
    "        df_eventos[col] = df_eventos[col].fillna(False)\n",
    "        columnas_bool.append(col)\n",
    "\n",
    "lista_cols_int = [\"match_id\", \"pass_recipient_id\", \"period\", \"player_id\", \"possession\", \"possession_team_id\", \"team_id\", \"type_id\"]\n",
    "for x in lista_cols_int:\n",
    "    df_eventos[x] = df_eventos[x].astype('Int64')\n",
    "    df_eventos[x].replace({pd.NA: None}, inplace=True)\n",
    "\n",
    "df_eventos.replace({pd.NA: None}, inplace=True)\n",
    "\n",
    "# Renombrar columnas\n",
    "df_eventos.rename(columns=({\"player_id\":\"playerid\",\n",
    "                            \"player\": \"nombre_completo_jugador\",\n",
    "                            \"team_id\": \"clubid\",\n",
    "                            \"team\": \"club\"}), inplace=True)\n",
    "\n",
    "# Carga BBDD\n",
    "load_dotenv()\n",
    "dbname = os.getenv(\"dbname\")\n",
    "user = os.getenv(\"user\")\n",
    "password = os.getenv(\"password\")\n",
    "(conn,cur) = conexion_postgres(dbname, user, password)\n",
    "insertar_datos_automatico(df_eventos,\"eventos\", cur, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4451e413",
   "metadata": {},
   "source": [
    "* Jugadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e4747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from src import insertar_datos_automatico, conexion_postgres, convertir_fechaeventos, combinar\n",
    "pd.set_option('display.max_columns', None)\n",
    "import psycopg2\n",
    "# Carga archivos\n",
    "df_jugadores = pd.read_csv(\"data/jugadores_info_normalizado.csv\")\n",
    "# Seleccionar columnas válidas\n",
    "df_jugadores_columnasok = df_jugadores[['playerID', 'playerName', 'playerFullName', 'birthplace',\n",
    "       'dateOfBirth', 'birthplaceCountry', 'age', 'height', 'foot', 'internationalTeam',\n",
    "       'internationalGames', 'internationalGoals', 'country', 'secondCountry', 'club',\n",
    "       'clubID', 'playerMainPosition', 'playerSecondPosition',\n",
    "       'playerThirdPosition', 'matches_played', 'starts', 'min', 'gls',\n",
    "       'ast', 'non_pen_gls', 'yellow_cards', 'red_cards',\n",
    "       'per90_gls', 'per90_ast', 'per90_non_pen_gls', 'subs',]]\n",
    "# Renombrar columnas\n",
    "df_jugadores_columnasok.rename(columns = {\n",
    "    'playerName': 'Nombre_Jugador',\n",
    "    'playerFullName': 'Nombre_Completo_Jugador',\n",
    "    'birthplace': 'Lugar_Nacimiento',\n",
    "    'dateOfBirth': 'Fecha_Nacimiento',\n",
    "    'birthplaceCountry': 'Pais_Nacimiento',\n",
    "    'age': 'Edad',\n",
    "    'height': 'Altura',\n",
    "    'foot': 'Pie_Dominante',\n",
    "    'internationalTeam': 'Equipo_Internacional',\n",
    "    'internationalGames': 'Partidos_Internacionales',\n",
    "    'internationalGoals': 'Goles_Internacionales',\n",
    "    'country': 'Pais',\n",
    "    'secondCountry': 'Segundo_Pais',\n",
    "    'club': 'Club',\n",
    "    'playerMainPosition': 'Posicion_Principal',\n",
    "    'playerSecondPosition': 'Posicion_Secundaria',\n",
    "    'playerThirdPosition': 'Posicion_Terciaria',\n",
    "    'matches_played' : 'Partidos_jugados', \n",
    "    'starts': 'Titularidades', \n",
    "    'min': 'Minutos', \n",
    "    'gls': 'Goles',\n",
    "    'ast': 'Asistencias',\n",
    "    'non_pen_gls': 'Goles_sin_penaltis',\n",
    "    'yellow_cards': 'Amarillas',\n",
    "    'red_cards': 'Rojas',\n",
    "    'per90_gls': 'Goles_por_90',\n",
    "    'per90_ast': 'Asistencias_por_90',\n",
    "    'per90_non_pen_gls': 'Goles_sin_penaltis_por_90',\n",
    "    'subs': 'Suplencias'\n",
    "}, inplace = True)\n",
    "# Quitar duplicados y cambiar tipos de dato\n",
    "df_jugadores_columnasok = df_jugadores_columnasok.dropna(subset=[\"playerID\"])\n",
    "df_jugadores_columnasok[\"Altura\"].replace(\"indeterminado\", np.nan, inplace=True)\n",
    "df_jugadores_columnasok[\"Altura\"] = df_jugadores_columnasok[\"Altura\"].str.replace(\",\", \".\").astype(float)\n",
    "df_jugadores_columnasok[\"Fecha_Nacimiento\"] = df_jugadores_columnasok[\"Fecha_Nacimiento\"] = pd.to_datetime(df_jugadores_columnasok[\"Fecha_Nacimiento\"])\n",
    "df_jugadores_columnasok[\"playerID\"] = df_jugadores_columnasok[\"playerID\"].astype(int)\n",
    "df_jugadores_columnasok[\"clubID\"] = df_jugadores_columnasok[\"clubID\"].astype(int)\n",
    "df_jugadores_columnasok[\"Partidos_Internacionales\"] = df_jugadores_columnasok[\"Partidos_Internacionales\"].astype('Int64')\n",
    "df_jugadores_columnasok[\"Goles_Internacionales\"] = df_jugadores_columnasok[\"Goles_Internacionales\"].astype('Int64')\n",
    "df_jugadores_columnasok[\"Titularidades\"] = df_jugadores_columnasok[\"Titularidades\"].astype('Int64')\n",
    "df_jugadores_columnasok[\"Goles\"] = df_jugadores_columnasok[\"Goles\"].astype('Int64')\n",
    "df_jugadores_columnasok[\"Asistencias\"] = df_jugadores_columnasok[\"Asistencias\"].astype('Int64')\n",
    "df_jugadores_columnasok[\"Amarillas\"] = df_jugadores_columnasok[\"Amarillas\"].astype('Int64')\n",
    "df_jugadores_columnasok[\"Rojas\"] = df_jugadores_columnasok[\"Rojas\"].astype('Int64')\n",
    "# Unificar filas duplicadas\n",
    "indices = df_jugadores_columnasok[df_jugadores_columnasok[\"playerID\"].duplicated()].index\n",
    "for x in indices:\n",
    "    fila_actual = df_jugadores_columnasok.loc[x]\n",
    "    fila_anterior = df_jugadores_columnasok.loc[x - 1]\n",
    "    # Aseguramos tipos escalar combinando columna por columna\n",
    "    fila_unificada = pd.Series(\n",
    "        {col: combinar(fila_actual[col], fila_anterior[col]) for col in df_jugadores_columnasok.columns})\n",
    "    # Reemplazar la fila anterior con la fila unificada\n",
    "    df_jugadores_columnasok.loc[x - 1] = fila_unificada\n",
    "# Eliminar filas duplicadas\n",
    "df_jugadores_columnasok = df_jugadores_columnasok.drop(index=indices).reset_index(drop=True)\n",
    "# Cambiar Nan por None\n",
    "df_jugadores_columnasok = df_jugadores_columnasok.astype(object).where(pd.notna(df_jugadores_columnasok), None)\n",
    "# Cargar BBDD\n",
    "load_dotenv()\n",
    "dbname = os.getenv(\"dbname\")\n",
    "user = os.getenv(\"user\")\n",
    "password = os.getenv(\"password\")\n",
    "(conn,cur) = conexion_postgres(dbname, user, password)\n",
    "insertar_datos_automatico(df_jugadores_columnasok,\"jugadores\", cur, conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e39037",
   "metadata": {},
   "source": [
    "* Partidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7a2df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from src import insertar_datos_automatico, conexion_postgres\n",
    "pd.set_option('display.max_columns', None)\n",
    "import psycopg2\n",
    "# Cargar archivos\n",
    "df_partidos = pd.read_csv(\"data/Team_Stats_Normalizado.csv\")\n",
    "df_completo = pd.read_csv(\"data/jugadores_info_normalizado.csv\")\n",
    "df_clubs = df_completo[[\"club\", \"clubID\"]].drop_duplicates().dropna().reset_index().drop(columns = [\"index\"])\n",
    "# Eliminar columnas\n",
    "df_partidos.drop(columns = [\"home_team\", \"away_team\"], inplace = True)\n",
    "# Crear diccionario para mapear nombres y los Ids de cada equipo\n",
    "diccionario_clubs = dict(zip(df_clubs[\"club\"], df_clubs[\"clubID\"]))\n",
    "df_partidos[\"id_club_local\"] = df_partidos[\"Local\"].map(diccionario_clubs)\n",
    "df_partidos[\"id_club_visitante\"] = df_partidos[\"Visitante\"].map(diccionario_clubs)\n",
    "df_partidos[\"id_club_stats\"] = df_partidos[\"Stats Equipo\"].map(diccionario_clubs)\n",
    "# Renombrar columnas\n",
    "df_partidos.rename(columns = {'Seleccionar esquema': 'Esquema'}, inplace = True)\n",
    "df_partidos.columns = df_partidos.columns.str.replace(' ', '_')\n",
    "df_prueba = df_partidos.copy()\n",
    "# Creamos una clave única por partido\n",
    "df_prueba['match_id'] = df_prueba['match_id'].astype(int)  # asegúrate de que sea tipo entero si no lo está\n",
    "# Separar columnas fijas (que no queremos duplicar) de métricas\n",
    "columnas_clave = ['Fecha', 'Partido', 'Resultado', 'match_id', 'Local', 'Visitante','Competición', 'Duración', 'id_club_local',  'id_club_visitante', 'id_club_stats']\n",
    "columnas_metricas = df_prueba.columns.difference(columnas_clave).tolist()\n",
    "\n",
    "# Pivotar el DataFrame para tener columnas por equipo\n",
    "df_local = df_prueba[df_partidos['Local'] == df_prueba['Stats_Equipo']].copy()\n",
    "df_visitante = df_prueba[df_partidos['Visitante'] == df_prueba['Stats_Equipo']].copy()\n",
    "\n",
    "# Renombramos columnas\n",
    "df_local = df_local.set_index('match_id')\n",
    "df_local.columns = [col + '_local' if col not in columnas_clave else col for col in df_local.columns]\n",
    "\n",
    "df_visitante = df_visitante.set_index('match_id')\n",
    "df_visitante.columns = [col + '_visitante' if col not in columnas_clave else col for col in df_visitante.columns]\n",
    "\n",
    "# Unimos los dos DataFrames\n",
    "df_final = df_local.join(df_visitante,lsuffix='_L', rsuffix='_V', how='inner').reset_index()\n",
    "#Eliminar columnas no necesarias\n",
    "df_final.drop(columns=([ 'Stats_Equipo_local',\n",
    " 'id_club_stats_L',\n",
    " 'Fecha_V',\n",
    " 'Partido_V',\n",
    " 'Resultado_V',\n",
    " 'Local_V',\n",
    " 'Visitante_V',\n",
    " 'Competición_V',\n",
    " 'Duración_V',\n",
    " 'Tiros_libres_con_remate.1_local',\n",
    " 'Tiros_libres_con_remate.1_visitante',\n",
    " 'Stats_Equipo_visitante',\n",
    " 'id_club_stats_V',\n",
    " 'id_club_local_V',\n",
    " 'id_club_visitante_V',\n",
    " 'Jornada_local']), inplace=True)\n",
    "# Renombrar columnas\n",
    "df_final.rename(columns={'Fecha_L':'Fecha',\n",
    " 'Partido_L':'Partido',\n",
    " 'Resultado_L': 'Resultado',\n",
    " 'Local_L':'Local',\n",
    " 'Visitante_L':'Visitante',\n",
    " 'Competición_L':'Competición',\n",
    " 'Duración_L':'Duración',\n",
    " 'Jornada_visitante':'Jornada',\n",
    " 'id_club_local_L' :'id_club_local',\n",
    " 'id_club_visitante_L' :'id_club_visitante',\n",
    "}, inplace=True)\n",
    "df_final.columns = df_final.columns.str.replace('%', 'porcentaje')\n",
    "df_final.columns = df_final.columns.str.replace(',', '')\n",
    "# Cargar BBDD\n",
    "load_dotenv()\n",
    "dbname = os.getenv(\"dbname\")\n",
    "user = os.getenv(\"user\")\n",
    "password = os.getenv(\"password\")\n",
    "(conn,cur) = conexion_postgres(dbname, user, password)\n",
    "insertar_datos_automatico(df_final,\"partidos\", cur, conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f730adee",
   "metadata": {},
   "source": [
    "* Lesiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from src import insertar_datos_automatico, conexion_postgres, convertir_fechaeventos\n",
    "import psycopg2\n",
    "import datetime\n",
    "# Cargar archivo\n",
    "df_lesiones = pd.read_csv(\"data/lesiones_completo_normalizado.csv\")\n",
    "# Renombrar columnnas y cambiar tipos de dato\n",
    "df_lesiones.rename(columns = {\n",
    "    'JUGADOR': 'Nombre_Jugador',\n",
    "    'href': 'Nombre_Completo_Jugador',\n",
    "    'equipo': 'Club',\n",
    "    'TIPO': 'Tipo_Lesion',\n",
    "    'SUB TIPO': 'Sub_Tipo_Lesion',\n",
    "    'TIPO_ID': 'Tipo_Lesion_ID',\n",
    "    'SUB_TIPO_ID': 'Sub_Tipo_Lesion_ID',\n",
    "    'DATA': 'Fecha_incio_lesion',\n",
    "    'FIM': 'Fecha_fin_lesion'\n",
    "}, inplace = True)\n",
    "df_lesiones = convertir_fechaeventos(df_lesiones)\n",
    "df_lesiones = df_lesiones.dropna(subset=[\"playerID\"])\n",
    "df_lesiones[\"playerID\"] = df_lesiones[\"playerID\"].astype(int)\n",
    "df_lesiones[\"clubID\"] = df_lesiones[\"clubID\"].astype(int)\n",
    "# Elegir unicamente lesiones\n",
    "df_lesiones = df_lesiones[df_lesiones[\"Tipo_Lesion\"] == \"Injury\"]\n",
    "# Quitar columnas no necesarias\n",
    "df_lesiones.drop(columns=([\"Tipo_Lesion_ID\", \"Tipo_Lesion\"]), inplace=True)\n",
    "# Renombrar\n",
    "df_lesiones.rename(columns = {\n",
    "    'Sub_Tipo_Lesion': 'Tipo_Lesion',\n",
    "    'Sub_Tipo_Lesion_ID': 'Tipo_Lesion_ID',\n",
    "}, inplace = True)\n",
    "# Crear tabla indice\n",
    "tabla_indice_lesiones = df_lesiones[[\"Tipo_Lesion\", \"Tipo_Lesion_ID\"]].drop_duplicates()\n",
    "df_lesiones[\"ID_Lesion\"] = df_lesiones[\"Nombre_Jugador\"].index\n",
    "# Modificar nombres para powerBI y agrupar en 15 Ids\n",
    "mapa_lesiones_grupo = {\n",
    "    # 1. Afecciones Abdominales y Gastrointestinales\n",
    "    29: \"Afecciones Abdominales y Gastrointestinales\",  # Stomach Problems\n",
    "    62: \"Afecciones Abdominales y Gastrointestinales\",  # Abdominal Problems\n",
    "\n",
    "    # 2. Afecciones del Tendón de Aquiles\n",
    "    33: \"Afecciones del Tendón de Aquiles\",  # Achilles tendon rupture\n",
    "    44: \"Afecciones del Tendón de Aquiles\",  # Achilles Heel Problems\n",
    "    45: \"Afecciones del Tendón de Aquiles\",  # Achilles tendon problems\n",
    "    61: \"Afecciones del Tendón de Aquiles\",  # Achilles Tendon Irritation\n",
    "\n",
    "    # 3. Lesiones de Cadera\n",
    "    54: \"Lesiones de Cadera\",  # Hip Injury\n",
    "    65: \"Lesiones de Cadera\",  # Hip Bruise\n",
    "\n",
    "    # 4. Lesiones de Cabeza, Cara y Cuello\n",
    "    13: \"Lesiones de Cabeza, Cara y Cuello\",  # Neck Injury\n",
    "    57: \"Lesiones de Cabeza, Cara y Cuello\",  # Cheekbone Fracture\n",
    "    68: \"Lesiones de Cabeza, Cara y Cuello\",  # Facial Fracture\n",
    "\n",
    "    # 5. Lesiones de Espalda\n",
    "    55: \"Lesiones de Espalda\",  # Back Injury\n",
    "\n",
    "    # 6. Lesiones de Hombro y Clavícula\n",
    "    46: \"Lesiones de Hombro y Clavícula\",  # Broken Collarbone\n",
    "    70: \"Lesiones de Hombro y Clavícula\",  # Shoulder Injury\n",
    "\n",
    "    # 7. Lesiones de Ingle, Aductores y Abductores\n",
    "    3:  \"Lesiones de Ingle, Aductores y Abductores\",  # Adductor Pain\n",
    "    6:  \"Lesiones de Ingle, Aductores y Abductores\",  # Tear in the abductor muscle\n",
    "    15: \"Lesiones de Ingle, Aductores y Abductores\",  # Groin Injury\n",
    "    38: \"Lesiones de Ingle, Aductores y Abductores\",  # Adductor Injury\n",
    "    53: \"Lesiones de Ingle, Aductores y Abductores\",  # Groin Problems\n",
    "\n",
    "    # 8. Lesiones de Ligamentos (Generales/No Articulares)\n",
    "    31: \"Lesiones de Ligamentos (Generales/No Articulares)\",  # Ligament Stretching\n",
    "    32: \"Lesiones de Ligamentos (Generales/No Articulares)\",  # Outer Ligament Problems\n",
    "\n",
    "    # 9. Lesiones de Mano y Dedos\n",
    "    47: \"Lesiones de Mano y Dedos\",  # Hand Injury\n",
    "    50: \"Lesiones de Mano y Dedos\",  # Thumb Injury\n",
    "\n",
    "    # 10. Lesiones de Muslo e Isquiotibiales\n",
    "    28: \"Lesiones de Muslo e Isquiotibiales\",  # Hamstring Injury\n",
    "    30: \"Lesiones de Muslo e Isquiotibiales\",  # Hamstring Strain\n",
    "    34: \"Lesiones de Muslo e Isquiotibiales\",  # Thigh Problems\n",
    "    67: \"Lesiones de Muslo e Isquiotibiales\",  # Thigh Muscle Strain\n",
    "\n",
    "    # 11. Lesiones de Pierna Inferior (Pantorrilla y Huesos)\n",
    "    2:  \"Lesiones de Pierna Inferior (Pantorrilla y Huesos)\",  # Calf Injury\n",
    "    11: \"Lesiones de Pierna Inferior (Pantorrilla y Huesos)\",  # Calf Problems\n",
    "    35: \"Lesiones de Pierna Inferior (Pantorrilla y Huesos)\",  # Broken Fibula\n",
    "    41: \"Lesiones de Pierna Inferior (Pantorrilla y Huesos)\",  # Broken Leg\n",
    "    42: \"Lesiones de Pierna Inferior (Pantorrilla y Huesos)\",  # Leg Injury\n",
    "\n",
    "    # 12. Lesiones de Rodilla (Complejo y Contusiones)\n",
    "    10: \"Lesiones de Rodilla (Complejo y Contusiones)\",  # Knee Problems\n",
    "    18: \"Lesiones de Rodilla (Complejo y Contusiones)\",  # Knee Bruise\n",
    "    36: \"Lesiones de Rodilla (Complejo y Contusiones)\",  # Knee Medial Ligament Tear\n",
    "    37: \"Lesiones de Rodilla (Complejo y Contusiones)\",  # Knee Injury\n",
    "    48: \"Lesiones de Rodilla (Complejo y Contusiones)\",  # Cruciate Ligament Injury\n",
    "    49: \"Lesiones de Rodilla (Complejo y Contusiones)\",  # Meniscus Tear\n",
    "    52: \"Lesiones de Rodilla (Complejo y Contusiones)\",  # Cruciate Ligament Tear\n",
    "    58: \"Lesiones de Rodilla (Complejo y Contusiones)\",  # Twisted knee\n",
    "    59: \"Lesiones de Rodilla (Complejo y Contusiones)\",  # Meniscus Injury\n",
    "\n",
    "    # 13. Lesiones de Tobillo, Pie y Dedos\n",
    "    4:  \"Lesiones de Tobillo, Pie y Dedos\",  # Ankle Problems\n",
    "    12: \"Lesiones de Tobillo, Pie y Dedos\",  # Foot Injury\n",
    "    22: \"Lesiones de Tobillo, Pie y Dedos\",  # Ankle Injury\n",
    "    26: \"Lesiones de Tobillo, Pie y Dedos\",  # Toe Injury\n",
    "    27: \"Lesiones de Tobillo, Pie y Dedos\",  # Ankle Sprain\n",
    "    40: \"Lesiones de Tobillo, Pie y Dedos\",  # Broken Toe\n",
    "\n",
    "    # 14. Lesiones Torácicas (Costillas, Pulmón)\n",
    "    25: \"Lesiones Torácicas (Costillas, Pulmón)\",  # Lung Contusion\n",
    "    43: \"Lesiones Torácicas (Costillas, Pulmón)\",  # Bruised Ribs\n",
    "\n",
    "    # 15. Otros y Afecciones Generales\n",
    "    5:  \"Otros y Afecciones Generales\",  # Rest\n",
    "    7:  \"Otros y Afecciones Generales\",  # Muscle Strain\n",
    "    8:  \"Otros y Afecciones Generales\",  # Muscle Injury\n",
    "    14: \"Otros y Afecciones Generales\",  # Torn Muscle Bundle\n",
    "    16: \"Otros y Afecciones Generales\",  # Knock\n",
    "    19: \"Otros y Afecciones Generales\",  # Muscular problems\n",
    "    20: \"Otros y Afecciones Generales\",  # Torn Muscle Fiber\n",
    "    21: \"Otros y Afecciones Generales\",  # Minor Knock\n",
    "    39: \"Otros y Afecciones Generales\",  # Fitness\n",
    "    51: \"Otros y Afecciones Generales\",  # Infection\n",
    "    60: \"Otros y Afecciones Generales\",  # Flu\n",
    "    63: \"Otros y Afecciones Generales\",  # Virus\n",
    "    64: \"Otros y Afecciones Generales\",  # Fever\n",
    "    69: \"Otros y Afecciones Generales\"   # Unknown Injury\n",
    "}\n",
    "tabla_indice_lesiones[\"Tipo_Lesion\"] = tabla_indice_lesiones[\"Tipo_Lesion_ID\"].map(mapa_lesiones_grupo)\n",
    "mapa_nombre_grupo_a_nuevo_id = {\n",
    "    \"Afecciones Abdominales y Gastrointestinales\": 1,\n",
    "    \"Afecciones del Tendón de Aquiles\": 2,\n",
    "    \"Lesiones de Cadera\": 3,\n",
    "    \"Lesiones de Cabeza, Cara y Cuello\": 4,\n",
    "    \"Lesiones de Espalda\": 5,\n",
    "    \"Lesiones de Hombro y Clavícula\": 6,\n",
    "    \"Lesiones de Ingle, Aductores y Abductores\": 7,\n",
    "    \"Lesiones de Ligamentos (Generales/No Articulares)\": 8,\n",
    "    \"Lesiones de Mano y Dedos\": 9,\n",
    "    \"Lesiones de Muslo e Isquiotibiales\": 10,\n",
    "    \"Lesiones de Pierna Inferior (Pantorrilla y Huesos)\": 11,\n",
    "    \"Lesiones de Rodilla (Complejo y Contusiones)\": 12,\n",
    "    \"Lesiones de Tobillo, Pie y Dedos\": 13,\n",
    "    \"Lesiones Torácicas (Costillas, Pulmón)\": 14,\n",
    "    \"Otros y Afecciones Generales\": 15\n",
    "}\n",
    "\n",
    "tabla_indice_lesiones[\"Tipo_Lesion_ID\"] = tabla_indice_lesiones[\"Tipo_Lesion\"].map(mapa_nombre_grupo_a_nuevo_id)\n",
    "tabla_indice_lesiones = tabla_indice_lesiones.groupby(\"Tipo_Lesion_ID\").count().reset_index()\n",
    "mapa_nuevo_id = {\n",
    "   1: \"Abdomen izquierdo\",\n",
    "    2: \"Pantorrilla derecha\",\n",
    "    3: \"Glúteo izquierdo\",\n",
    "    4: \"Cabeza delantera\",\n",
    "    5: \"Erector de la columna izquierdo\",\n",
    "    6: \"Deltoide izquierdo delantero\",\n",
    "    7: \"Aductor largo izquierdo\",\n",
    "    8: \"Recto femoral izquierdo\",\n",
    "    9: \"Flexor Digitorum Izquierdo\",\n",
    "    10: \"Bíceps femoral izquierdo\",\n",
    "    11: \"Pantorrilla izquierda\",\n",
    "    12: \"Rodilla izquierda delantera\",\n",
    "    13: \"Tibial anterior izquierdo\",\n",
    "    14: \"Erector de la columna derecho\",\n",
    "    15: \"Cabeza trasera\"\n",
    "}\n",
    "tabla_indice_lesiones[\"Tipo_Lesion\"] = tabla_indice_lesiones[\"Tipo_Lesion_ID\"].map(mapa_nuevo_id)\n",
    "df_lesiones[\"Tipo_Lesion\"] = df_lesiones[\"Tipo_Lesion_ID\"].map(mapa_lesiones_grupo)\n",
    "df_lesiones[\"Tipo_Lesion_ID\"] = df_lesiones[\"Tipo_Lesion\"].map(mapa_nombre_grupo_a_nuevo_id)\n",
    "df_lesiones[\"Tipo_Lesion\"] = df_lesiones[\"Tipo_Lesion_ID\"].map(mapa_nuevo_id)\n",
    "df_lesiones[\"Tipo_Lesion\"].unique()\n",
    "# Cargar BBDD\n",
    "load_dotenv()\n",
    "dbname = os.getenv(\"dbname\")\n",
    "user = os.getenv(\"user\")\n",
    "password = os.getenv(\"password\")\n",
    "(conn,cur) = conexion_postgres(dbname, user, password)\n",
    "insertar_datos_automatico(df_lesiones,\"lesiones\", cur, conn)\n",
    "insertar_datos_automatico(tabla_indice_lesiones,\"Lesiones_indice\", cur, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed70178",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e965e611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías y crear conexión con la BBDD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import src as src\n",
    "from src import conexion_postgres\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import time\n",
    "pd.set_option('display.max_columns', None)\n",
    "load_dotenv()\n",
    "dbname = os.getenv(\"dbname\")\n",
    "user = os.getenv(\"user\")\n",
    "password = os.getenv(\"password\")\n",
    "(conn,cur) = conexion_postgres(dbname, user, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538c4ab4",
   "metadata": {},
   "source": [
    "* Estadísticas partidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e173ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traer datos y hacer df\n",
    "cur.execute(\"SELECT * FROM partidos\")\n",
    "datos_partidos = cur.fetchall()\n",
    "columnas_partidos = [desc[0] for desc in cur.description]\n",
    "df_partidos = pd.DataFrame(datos_partidos, columns=columnas_partidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68484acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificar df para ver columnas numericas y agupar por Athletic Club vs Liga\n",
    "numericas = df_partidos.select_dtypes(include=np.number).columns.tolist()\n",
    "df_numericas = df_partidos[numericas]\n",
    "columnas_id_club_local = [\"id_club_local\"]\n",
    "columnas_finales_local = list(set(numericas + columnas_id_club_local))\n",
    "df_final_local = df_partidos[columnas_finales_local]\n",
    "columnas_id_club_local_1 = df_final_local.columns.tolist()\n",
    "columnas_id_club_local_1_ord = sorted(columnas_id_club_local_1)\n",
    "df_final_local_ordenado = df_final_local[columnas_id_club_local_1_ord]\n",
    "columnas_id_club_visitante = [\"id_club_visitante\"]\n",
    "columnas_finales_visitante = list(set(numericas + columnas_id_club_visitante))\n",
    "df_final_visitante = df_partidos[columnas_finales_visitante]\n",
    "columnas_id_club_visitante_1 = df_final_visitante.columns.tolist()\n",
    "columnas_id_club_visitante_1 = sorted(columnas_id_club_visitante_1)\n",
    "df_final_visitante_ordenado = df_final_visitante[columnas_id_club_visitante_1]\n",
    "df_final_local_ordenado_medias = df_final_local_ordenado.groupby(\"id_club_local\").mean().reset_index()\n",
    "ath_local = df_final_local_ordenado_medias.iloc[9]\n",
    "mean_row_local = df_final_local_ordenado_medias.mean(numeric_only=True)\n",
    "for col in df_final_local_ordenado_medias.columns:\n",
    "    if col not in mean_row_local:\n",
    "        mean_row_local[col] = None  # o np.nan\n",
    "mean_row_ord = mean_row_local[ath_local.index]\n",
    "df_ath_local = pd.DataFrame([ath_local, mean_row_ord])\n",
    "df_ath_local.replace(pd.NA, \"Local\", inplace=True)\n",
    "df_ath_local.rename(columns=({\"id_club_local\":\"id_club\"}), inplace=True)\n",
    "mean_row_local = df_final_local_ordenado_medias.mean(numeric_only=True)\n",
    "for col in df_final_local_ordenado_medias.columns:\n",
    "    if col not in mean_row_local:\n",
    "        mean_row_local[col] = None\n",
    "df_final_visitante_ordenado_medias = df_final_visitante_ordenado.groupby(\"id_club_visitante\").mean().reset_index()\n",
    "ath_visitante = df_final_visitante_ordenado_medias.iloc[9]\n",
    "mean_row_visitante = df_final_visitante_ordenado_medias.mean(numeric_only=True)\n",
    "for col in df_final_visitante_ordenado_medias.columns:\n",
    "    if col not in mean_row_visitante:\n",
    "        mean_row_visitante[col] = None  # o np.nan\n",
    "mean_row_visitante_ord = mean_row_visitante[ath_visitante.index]\n",
    "df_ath_visitante = pd.DataFrame([ath_visitante, mean_row_visitante_ord])\n",
    "df_ath_visitante.replace(pd.NA, \"Visitante\", inplace=True)\n",
    "df_ath_visitante.rename(columns=({\"id_club_visitante\":\"id_club\"}), inplace=True)\n",
    "# Ver datos como local\n",
    "df_ath_local\n",
    "# Ver datos como visitante\n",
    "df_ath_visitante\n",
    "# Unir a datos como local\n",
    "df_ath_vs_liga = pd.concat([df_ath_local, df_ath_visitante])\n",
    "# Datos vs Liga\n",
    "df_ath_vs_liga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f07e5",
   "metadata": {},
   "source": [
    "* Lesiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c960c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traer datos\n",
    "cur.execute(\"SELECT * FROM lesiones\")\n",
    "datos_lesiones = cur.fetchall()\n",
    "columnas_lesiones = [desc[0] for desc in cur.description]\n",
    "df_lesiones = pd.DataFrame(datos_lesiones, columns=columnas_lesiones)\n",
    "# Crear df general y uno del equipo\n",
    "prueba = df_lesiones.groupby([\"club\", \"tipo_lesion_id\"])[\"playerid\"].count().reset_index()\n",
    "prueba_ath = df_lesiones[df_lesiones[\"club\"] == \"Athletic Club\"]\n",
    "ath_lesiones = prueba_ath.groupby(\"tipo_lesion\")[\"playerid\"].count().reset_index()\n",
    "ath_lesiones.rename(columns = {\"playerid\":\"n_lesiones\"}, inplace=True)\n",
    "# Nº de lesiones\n",
    "ath_lesiones\n",
    "# Comparar con resto de la liga\n",
    "liga_lesiones = df_lesiones.groupby(\"tipo_lesion\")[\"playerid\"].count().reset_index()\n",
    "liga_lesiones.rename(columns = {\"playerid\":\"n_lesiones\"}, inplace=True)\n",
    "liga_lesiones = liga_lesiones.groupby(\"tipo_lesion\").mean().reset_index()\n",
    "liga_lesiones\n",
    "comparacion_lesiones = pd.merge(liga_lesiones, ath_lesiones, how= \"left\", on='tipo_lesion')\n",
    "comparacion_lesiones.rename(columns = {\"n_lesiones_x\":\"lesiones_liga\", \"n_lesiones_y\":\"lesiones_ath\"}, inplace=True)\n",
    "comparacion_lesiones = comparacion_lesiones.sort_values(by='lesiones_ath', ascending=False)\n",
    "comparacion_lesiones.head(15)\n",
    "# Ver lesiones por jugador\n",
    "prueba_ath.groupby([\"nombre_jugador\", \"tipo_lesion\"])[\"tipo_lesion_id\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c3c135",
   "metadata": {},
   "source": [
    "* Jugadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057aa871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga datos\n",
    "cur.execute(\"SELECT * FROM jugadores\")\n",
    "datos_jugadores = cur.fetchall()\n",
    "columnas_jugadores = [desc[0] for desc in cur.description]\n",
    "df_jugadores = pd.DataFrame(datos_jugadores, columns=columnas_jugadores)\n",
    "# Hacer df para el equipo\n",
    "df_jugadores_ath = df_jugadores[df_jugadores[\"club\"] == \"Athletic Club\"]\n",
    "# Cambiar fechas\n",
    "df_jugadores_ath[\"fecha_nacimiento\"] = pd.to_datetime(df_jugadores_ath[\"fecha_nacimiento\"], errors='coerce')\n",
    "df_jugadores[\"fecha_nacimiento\"] = pd.to_datetime(df_jugadores[\"fecha_nacimiento\"], errors='coerce')\n",
    "# Crear edad en 2015\n",
    "df_jugadores[\"edad_liga\"] = df_jugadores[\"fecha_nacimiento\"].dt.year\n",
    "df_jugadores_ath[\"edad_liga\"] = df_jugadores_ath[\"fecha_nacimiento\"].dt.year\n",
    "# Visualizar datos tanto de equipo como de la Liga en general\n",
    "df_jugadores_ath.describe()\n",
    "df_jugadores.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
